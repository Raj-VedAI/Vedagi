
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Ved AGI - Technology</title>
  <meta name="description" content="The Architecture of Human-Aligned Intelligence">
  <link rel="stylesheet" href="../assets/style.css">
</head>
<body>
  <header>
    <img src="../assets/logo.svg" alt="Ved AGI Logo" class="logo">
    <nav>
      <a href="../index.html">Home</a>
      <a href="../mission/index.html">Mission</a>
      <a href="index.html" class="active">Technology</a>
      <a href="../roadmap/index.html">Roadmap</a>
      <a href="../community/index.html">Community</a>
    </nav>
  </header>
  <main>
    <section class="hero">
      <h1>The Architecture of Human-Aligned Intelligence</h1>
      <p>We are combining the latest breakthroughs in machine learning with a uniquely transparent development model.</p>
    </section>
    <section>
      <h2>Foundational Model Strategy</h2>
      <p>Ved AGI begins with large-scale foundational models, optimized for reasoning, planning, creativity, and learning across domains.</p>
    </section>
    <section>
      <h2>Training Approach</h2>
      <ul>
        <li>Transformer-based neural architectures</li>
        <li>Reinforcement Learning from Human Feedback (RLHF)</li>
        <li>Low-Rank Adaptation (LoRA) fine-tuning</li>
        <li>Multi-modal capabilities (text, code, vision, audio in roadmap)</li>
      </ul>
    </section>
    <section>
      <h2>Open Source + Open Science</h2>
      <p>By publishing research, releasing models, and building in the open, we ensure the global community contributes to — and benefits from — Ved AGI.</p>
    </section>
    <section>
      <h2>Safety Layers</h2>
      <ul>
        <li>Guardrails for harmful outputs</li>
        <li>Bias and fairness testing pipelines</li>
        <li>Interpretability dashboards</li>
      </ul>
    </section>
  </main>
  <footer>
    <p>© 2025 Ved AGI. All rights reserved.</p>
  </footer>
</body>
</html>
